


# summary for paper VGG16

this is a summary for paper:
ref: http://noahsnail.com/2017/08/17/2017-08-17-VGG%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E6%96%87%E7%89%88/


## 0. 摘要
使用非常小的（3x3）卷积滤波器架构对网络深度的影响。

## 1. 引言
卷积网络（ConvNets）近来在大规模图像和视频识别方面取得了巨大成功。随着ConvNets在计算机视觉领域越来越商品化，为了达到更好的准确性，已经进行了许多尝试来改进Krizhevsky等人表现最佳的提交使用了更小的感受窗口尺寸和更小的第一卷积层步长。另一条改进措施在整个图像和多个尺度上对网络进行密集地训练和测试。在本文中，我们解决了ConvNet架构设计的另一个重要方面——其深度。为此，我们修正了架构的其它参数，并通过添加更多的卷积层来稳定地增加网络的深度，这是可行的，因为在所有层中使用非常小的（3×3）卷积滤波器。


## 2. ConvNet 配置
### 2.1
**输入**
在训练期间，ConvNet的输入是固定的 224x224 RGB图像。
**预处理**
唯一的预处理是从每个像素中减去在训练集上计算的 RGB 均值。
**卷积滤波**
使用 3x3 的滤波器（捕获上下，左右，中心概念是最小尺寸）。卷积步长固定为 1个像素。
卷积层输入的空间填充要满足卷积之后保留空间分辨率，即3×3卷积层的填充为1个像素。(js:实际上就是想输出 224*224 的图片，即让原图片上的所有像素点都进行卷积滤波)
其中一种配置使用了 1x1 卷积滤波器，可以看作是输入通道的线性变换。
**池化**
空间池化有5个最大池化层，放在一些卷积层之后。并不是所有卷积层后面都有最大池化层。池化窗口 2*2, 步长为 2.
**全连接**
一堆卷积层（在不同架构中具有不同深度）之后是三个全连接（FC）层：
前两个每个有 4096 个通道。第三个执行 1000 维 ILSVRC 分类，因此包含 1000 个通道，一个通道对应一个类别。
*ILSVRC 分类： ImageNet Large Scale Visual Recognition Challenge*
**soft-max**
最后一层是 soft-max 层。所有网络中全连接层的配置是相同的。

**修正**
所有隐藏层都配备了修正（ReLU) 非线性。
只有一个网络有局部相应规范化（LRN)：在第4节能够看到这种规范化不能提高 ILSVRC数据集上的性能，但增加了内存消耗和计算时间。
在应用的地方，LRN层的参数是（Krizhevsky等，2012）的参数。

![avatar](../jiasheng/image/vgg_net_struct_1.png)


### 2.2 配置

![avatar](../jiasheng/image/vgg16_2_2_1.png)
https://www.jianshu.com/p/280c6a6f2594
图中将按照网络名称（A~E)来提及网络。所有配置都遵循 2.1 节设计的通用设计，并且深度不同：从 A 网络中的 11 个加权层（8个卷积层和3个 FC 层）到网络E中的 19个加权层（16个卷积层和3个FC层）。卷积层的宽度（通道数）相当小，从第一层中的 64开始，然后在每个最大池化层之后增加 2 倍，直到达到 512.


### 2.3 讨论
整个网络使用非常小的 3x3 感受野，与输入的像素进行卷积（步长为1）。很容易看到 2个 3x3 卷积层的对迪特（没有空间池化）有 5x5 的有效感受野；这样 3个 3x3 卷积层就有 7x7 的有效感受野。
首先，结合三个非线性修正曾，而不是单一的，这使得决策函数更具有判别性。其次，我们减少参数的数量：假设三层 3x3 卷积对贴的输入和输出有 C 个通道，对叠卷积层的参数为 3*(3^2*C^2) = 27*C^2 个权重，单个 7x7 卷积层将需要 7^2*C^2=27*C^2 个权重，即参数多 81%. 这可以看作是对7×7卷积滤波器进行正则化，迫使它们通过3×3滤波器（在它们之间注入非线性）进行分解。

结合1×1卷积层（配置C，表1）是增加决策函数非线性而不影响卷积层感受野的一种方式。即使在我们的案例下，1×1卷积基本上是在相同维度空间上的线性投影（输入和输出通道的数量相同），由修正函数引入附加的非线性.

GooLeNet 基于非常深的ConvNets（22个权重层）和小卷积滤波器（除了3×3，它们也使用了1×1和5×5卷积）。



## 3.分类框架

### 3.1 训练
ConvNet训练过程通常遵循Krizhevsky等人（除了从多尺度训练图像中对输入裁剪图像进行采样外，如下文所述）。也就是说, 通过使用具有动量的小批量梯度下降优化多项式逻辑回归目标函数来进行训练。批量大小设为256，动量为0.9。训练通过权重衰减（L2惩罚乘子设定为5⋅10−4）进行正则化，前两个全连接层执行丢弃正则化（丢弃率设定为0.5）。学习率初始设定为10^(−2)，然后当验证集准确率停止改善时，减少10倍。学习率总共降低3次，学习在37万次迭代后停止（74个epochs）。


网络权重的初始化是重要的，因为由于深度网络中梯度的不稳定，不好的初始化可能会阻碍学习。方案是开始用网络A进行训练，初始值是随机的。然后，当进行更深的架构时，用网络A的层初始化前四层卷积层和最后三层全连接层，中间其他层采用随机初始化。
允许学习率在学习过程中发生改变。
对随机初始化，从均值为 0， 方差为 0.01 的正态分布中采样权重。
偏置初始化为0.

为了获取 224x224 大小的图片，它们从归一化的训练图像中被随机裁剪（每个图像每次 SGD 迭代进行一次裁剪）。为了进一步增强训练集，对裁剪后的图片进行水平反转，和 RGB颜色的偏移。

图像归一化：调整训练图像的大小。令S是等轴归一化的训练图像的最小边，ConvNet输入从S中裁剪（我们也将S称为训练尺度）。对于S=224，裁剪图像将捕获整个图像的统计数据，完全扩展训练图像的最小边。对于 S>>224, 裁剪图像将对应于图像的一小部分，包含小对象或对象的一部分。

采用两种方法设置训练集尺度：
1. 修正对应单尺度训练的 S。（采样裁剪图像中的图像内容仍然可以表示多尺度图像统计）
   - 实验中，评估使用 S=256 和 S=384 两种固定尺度的训练模型。
   - 给定 ConvNet 的配置，先用 S=256 训练网络，在用此训练结果作为 S=384 的初始值。
2. 多尺度训练。
   - 其中每个训练图片通过从 [Smin, Smax] (Smin=256, Smax=512)随机采样 S来单独进行归一化。这会使图像中的目标可能具有不同的大小，可以作为通过尺度抖动进行训练集增强器。
   - 为了速度，训练多尺度的时候，使用 S=384

### 3.2 测试
分类方式：
1. 等轴的归一化到预定义的最小图像边，表示为 Q。（测试尺度）
2. 网络以类似于（Sermanet等人，2014）的方式密集地应用于归一化的测试图像上。即，全连接层首先被转换成卷积层（第一FC层转换到7×7卷积层，最后两个FC层转换到1×1卷积层）
3. 将所得到的全卷积网络应用于整个（未裁剪）图像上。
4. 结果是类得分图的通道数等于类别的数量，以及取决于输入图像大小的可变空间分辨率。
5. 为了获得图像的类别分数的固定大小的向量，类得分图在空间上平均（和池化）
6. 通过水平翻转图像来增强测试集；将原始图像和翻转图像的soft-max类后验进行平均，以获得图像的最终分数。

由于全卷积层应用在整个图像上，不需要在测试时对采样多个裁剪图像。因为效率低。
使用大量的裁剪图像可以提高准确度。全卷积网络相比，它使输入图像的采样更精细。
由于不同的卷积边界条件，多裁剪图像评估是密集评估的补充。
当将ConvNet应用于裁剪图像时，卷积特征图用零填充，而在密集评估的情况下，相同裁剪图像的填充自然会来自于图像的相邻部分（由于卷积和空间池化），这大大增加了整个网络的感受野，因此捕获了更多的上下文。


### 3.3 实现细节
公开的 C++ caffe 工具箱，多 GPU进行训练。并行处理，处理后进行平均。


## 4. 分类实验
数据集包括1000个类别的图像，并分为三组：训练（130万张图像），验证（5万张图像）和测试（留有类标签的10万张图像）。
使用两个措施评估分类性能：top-1和top-5错误率。前者是多类分类误差，即不正确分类图像的比例；后者是ILSVRC中使用的主要评估标准，并且计算为图像真实类别在前5个预测类别之外的图像比例。



## 5 结论
证实了深度在视觉表示中的重要性